"""
word_collector.py - ì•¼ê¸ˆì•¼ê¸ˆ ë‹¨ì–´ ìˆ˜ì§‘ ì‹œìŠ¤í…œ (í™•ì¥íŒ)

ë§¤ì¼ ë„¤ì´ë²„ ì‚¬ì „ì—ì„œ ë‹¨ì–´+ì˜ˆë¬¸ì„ ìˆ˜ì§‘í•˜ì—¬ ë¡œì»¬ JSON DBì— ì €ì¥í•©ë‹ˆë‹¤.
- JLPT ë ˆë²¨ë³„ (N5~N1)
- í•™êµê¸‰ë³„ (ì¤‘í•™êµ, ê³ ë“±í•™êµ)
- ì£¼ì œë³„ (ì—¬í–‰, ìŒì‹, ë¹„ì¦ˆë‹ˆìŠ¤ ë“±)
- í•œ ë²ˆì— 300~500ê°œ ë‹¨ì–´ ìˆ˜ì§‘ ê°€ëŠ¥
"""

import os
import json
import urllib.request
import urllib.parse
from datetime import datetime
from typing import List, Dict, Optional
import time

# ì„¤ì •
DATA_DIR = os.path.join(os.path.dirname(__file__), 'data')
COLLECTED_WORDS_FILE = os.path.join(DATA_DIR, 'collected_words.json')

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ (í•˜ë“œì½”ë”© ê¸ˆì§€!)
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
    print("âš ï¸ NAVER API keys not found. Set NAVER_CLIENT_ID and NAVER_CLIENT_SECRET environment variables.")

# ==========================================
# ìˆ˜ì§‘ ëŒ€ìƒ ì¹´í…Œê³ ë¦¬ ì •ì˜ (ëŒ€í­ í™•ì¥)
# ==========================================
COLLECTION_CATEGORIES = {
    # JLPT N5 (ê°€ì¥ ê¸°ì´ˆ) - ì•½ 100ë‹¨ì–´
    "jlpt_n5": {
        "name": "JLPT N5 ê¸°ì´ˆ",
        "level": "beginner",
        "seed_words": [
            # ì¸ì‚¬/ê¸°ë³¸
            "ã“ã‚“ã«ã¡ã¯", "ã‚ã‚ŠãŒã¨ã†", "ã™ã¿ã¾ã›ã‚“", "ã¯ã„", "ã„ã„ãˆ", "ãŠã¯ã‚ˆã†", "ã“ã‚“ã°ã‚“ã¯", "ã•ã‚ˆã†ãªã‚‰",
            # ìˆ«ì
            "ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å", "ç™¾", "åƒ", "ä¸‡",
            # ìš”ì¼/ì‹œê°„
            "æœˆæ›œæ—¥", "ç«æ›œæ—¥", "æ°´æ›œæ—¥", "æœ¨æ›œæ—¥", "é‡‘æ›œæ—¥", "åœŸæ›œæ—¥", "æ—¥æ›œæ—¥", "ä»Šæ—¥", "æ˜æ—¥", "æ˜¨æ—¥",
            # ê°€ì¡±
            "çˆ¶", "æ¯", "å…„", "å§‰", "å¼Ÿ", "å¦¹", "å®¶æ—", "å­ä¾›", "ç”·", "å¥³",
            # ê¸°ë³¸ ë™ì‚¬
            "é£Ÿã¹ã‚‹", "é£²ã‚€", "è¦‹ã‚‹", "èã", "èª­ã‚€", "æ›¸ã", "è©±ã™", "è¡Œã", "æ¥ã‚‹", "å¸°ã‚‹",
            "è²·ã†", "å£²ã‚‹", "ä½œã‚‹", "ä½¿ã†", "å¾…ã¤", "ä¼šã†", "åˆ†ã‹ã‚‹", "çŸ¥ã‚‹", "æ€ã†", "è€ƒãˆã‚‹",
            # ê¸°ë³¸ í˜•ìš©ì‚¬
            "å¤§ãã„", "å°ã•ã„", "æ–°ã—ã„", "å¤ã„", "é«˜ã„", "å®‰ã„", "è‰¯ã„", "æ‚ªã„", "é•·ã„", "çŸ­ã„",
            "æš‘ã„", "å¯’ã„", "ç†±ã„", "å†·ãŸã„", "ç”˜ã„", "è¾›ã„", "ç¾å‘³ã—ã„", "æ¥½ã—ã„", "å¬‰ã—ã„", "æ‚²ã—ã„"
        ]
    },
    
    # JLPT N4 (ì´ˆê¸‰) - ì•½ 150ë‹¨ì–´
    "jlpt_n4": {
        "name": "JLPT N4 ì´ˆê¸‰",
        "level": "elementary",
        "seed_words": [
            # í•™êµ/êµìœ¡
            "å­¦æ ¡", "å¤§å­¦", "å…ˆç”Ÿ", "å­¦ç”Ÿ", "æˆæ¥­", "å‹‰å¼·", "å®¿é¡Œ", "è©¦é¨“", "æ•™å®¤", "å›³æ›¸é¤¨",
            # ì§ì—…/ì¼
            "ä»•äº‹", "ä¼šç¤¾", "ç¤¾é•·", "ç¤¾å“¡", "åº—å“¡", "åŒ»è€…", "çœ‹è­·å¸«", "è­¦å¯Ÿ", "é‹è»¢æ‰‹", "æ–™ç†äºº",
            # ì¥ì†Œ
            "é§…", "ç©ºæ¸¯", "ç—…é™¢", "éŠ€è¡Œ", "éƒµä¾¿å±€", "è­¦å¯Ÿç½²", "æ¶ˆé˜²ç½²", "å¸‚å½¹æ‰€", "å…¬åœ’", "ç¥ç¤¾",
            # êµí†µ
            "é›»è»Š", "ãƒã‚¹", "ã‚¿ã‚¯ã‚·ãƒ¼", "é£›è¡Œæ©Ÿ", "èˆ¹", "è‡ªè»¢è»Š", "è»Š", "é“", "ä¿¡å·", "äº¤å·®ç‚¹",
            # ìŒì‹
            "ã”é£¯", "ãƒ‘ãƒ³", "è‚‰", "é­š", "é‡èœ", "æœç‰©", "åµ", "ç‰›ä¹³", "æ°´", "ãŠèŒ¶",
            # ì¼ìƒ ë™ì‚¬
            "èµ·ãã‚‹", "å¯ã‚‹", "ç€ã‚‹", "è„±ã", "æ´—ã†", "ç£¨ã", "æƒé™¤ã™ã‚‹", "æ´—æ¿¯ã™ã‚‹", "æ–™ç†ã™ã‚‹", "è²·ã„ç‰©ã™ã‚‹",
            "åƒã", "ä¼‘ã‚€", "éŠã¶", "æ³³ã", "èµ°ã‚‹", "æ­©ã", "ç™»ã‚‹", "é™ã‚Šã‚‹", "ä¹—ã‚‹", "å‡ºã‚‹",
            # ì¼ìƒ í˜•ìš©ì‚¬/ë¶€ì‚¬
            "é™ã‹", "è³‘ã‚„ã‹", "ä¾¿åˆ©", "ä¸ä¾¿", "å±é™º", "å®‰å…¨", "ç°¡å˜", "é›£ã—ã„", "æœ‰å", "ç‰¹åˆ¥"
        ]
    },
    
    # JLPT N3 (ì¤‘ê¸‰) - ì•½ 200ë‹¨ì–´
    "jlpt_n3": {
        "name": "JLPT N3 ì¤‘ê¸‰",
        "level": "intermediate",
        "seed_words": [
            # ê°ì •/ì‹¬ë¦¬
            "æ„Ÿå‹•", "æ„Ÿè¬", "å¿ƒé…", "ç·Šå¼µ", "èˆˆå¥®", "å¤±æœ›", "å¾Œæ‚”", "æº€è¶³", "ä¸æº€", "é©šã",
            # ì‚¬íšŒ/ê´€ê³„
            "å‹äºº", "æ‹äºº", "å¤«å©¦", "è¦ªæˆš", "éš£äºº", "ä¸Šå¸", "éƒ¨ä¸‹", "åŒåƒš", "å…ˆè¼©", "å¾Œè¼©",
            # ë¹„ì¦ˆë‹ˆìŠ¤
            "ä¼šè­°", "å ±å‘Š", "é€£çµ¡", "ç›¸è«‡", "æ±ºå®š", "è¨ˆç”»", "ç›®æ¨™", "çµæœ", "æˆåŠŸ", "å¤±æ•—",
            # ìì—°/í™˜ê²½
            "è‡ªç„¶", "ç’°å¢ƒ", "æ°—å€™", "å¤©æ°—", "å­£ç¯€", "æ˜¥", "å¤", "ç§‹", "å†¬", "é›¨",
            # ê±´ê°•/ì˜ë£Œ
            "å¥åº·", "ç—…æ°—", "ç—‡çŠ¶", "æ²»ç™‚", "è–¬", "æ³¨å°„", "æ‰‹è¡“", "å…¥é™¢", "é€€é™¢", "æ¤œæŸ»",
            # ì¶”ìƒì  ê°œë…
            "æ„å‘³", "ç†ç”±", "åŸå› ", "çµæœ", "é–¢ä¿‚", "å½±éŸ¿", "åŠ¹æœ", "ä¾¡å€¤", "æ„è¦‹", "è€ƒãˆ"
        ]
    },
    
    # JLPT N2 (ìƒê¸‰)
    "jlpt_n2": {
        "name": "JLPT N2 ìƒê¸‰",
        "level": "advanced",
        "seed_words": [
            "çµŒæ¸ˆ", "æ”¿æ²»", "ç¤¾ä¼š", "æ–‡åŒ–", "æ­´å²", "ç§‘å­¦", "æŠ€è¡“", "ç”£æ¥­", "è²¿æ˜“", "æŠ•è³‡",
            "å›½éš›", "å¤–äº¤", "æ¡ç´„", "æ³•å¾‹", "åˆ¶åº¦", "æ”¹é©", "ç™ºå±•", "æˆé•·", "ç«¶äº‰", "å”åŠ›",
            "ç’°å¢ƒå•é¡Œ", "æ¸©æš–åŒ–", "è³‡æº", "ã‚¨ãƒãƒ«ã‚®ãƒ¼", "å…¬å®³", "ãƒªã‚µã‚¤ã‚¯ãƒ«", "æŒç¶šå¯èƒ½", "ä¿è­·", "å¯¾ç­–", "è§£æ±º"
        ]
    },
    
    # JLPT N1 (ìµœìƒê¸‰)
    "jlpt_n1": {
        "name": "JLPT N1 ìµœìƒê¸‰",
        "level": "expert",
        "seed_words": [
            "æ¦‚å¿µ", "æŠ½è±¡", "å…·ä½“", "è«–ç†", "çŸ›ç›¾", "çš®è‚‰", "é¢¨åˆº", "æ¯”å–©", "æš—ç¤º", "è±¡å¾´",
            "å“²å­¦", "å€«ç†", "é“å¾³", "ä¾¡å€¤è¦³", "ä¸–ç•Œè¦³", "äººç”Ÿè¦³", "ç†å¿µ", "ç†æƒ³", "ç¾å®Ÿ", "æœ¬è³ª"
        ]
    },
    
    # ì¤‘í•™êµ ê¸°ì´ˆ
    "middle_school": {
        "name": "ì¤‘í•™êµ ì¼ë³¸ì–´",
        "level": "school_middle",
        "seed_words": [
            "æ•™ç§‘æ›¸", "ãƒãƒ¼ãƒˆ", "é‰›ç­†", "æ¶ˆã—ã‚´ãƒ ", "å®šè¦", "æ™‚é–“å‰²", "çµ¦é£Ÿ", "éƒ¨æ´»å‹•", "ä½“è‚²", "éŸ³æ¥½",
            "æ•°å­¦", "å›½èª", "ç†ç§‘", "ç¤¾ä¼š", "è‹±èª", "ç¾è¡“", "å®¶åº­ç§‘", "æŠ€è¡“", "é“å¾³", "ç·åˆ",
            "å…¥å­¦", "å’æ¥­", "é€²å­¦", "å—é¨“", "åˆæ ¼", "ä¸åˆæ ¼", "æˆç¸¾", "é€šçŸ¥è¡¨", "ãƒ†ã‚¹ãƒˆ", "æœŸæœ«"
        ]
    },
    
    # ê³ ë“±í•™êµ ê¸°ì´ˆ
    "high_school": {
        "name": "ê³ ë“±í•™êµ ì¼ë³¸ì–´",
        "level": "school_high",
        "seed_words": [
            "é€²è·¯", "å°±è·", "å¤§å­¦å—é¨“", "ã‚»ãƒ³ã‚¿ãƒ¼è©¦é¨“", "æ¨è–¦", "é¢æ¥", "å¿—æœ›æ ¡", "åå·®å€¤", "äºˆå‚™æ ¡", "å¡¾",
            "æ–‡ç³»", "ç†ç³»", "å°‚æ”»", "ç ”ç©¶", "è«–æ–‡", "ç™ºè¡¨", "è¨è«–", "ãƒ—ãƒ¬ã‚¼ãƒ³", "ãƒ¬ãƒãƒ¼ãƒˆ", "èª²é¡Œ"
        ]
    },
    
    # ì—¬í–‰ ì¼ë³¸ì–´
    "travel": {
        "name": "ì—¬í–‰ ì¼ë³¸ì–´",
        "level": "practical",
        "seed_words": [
            "ç©ºæ¸¯", "é§…", "ãƒ›ãƒ†ãƒ«", "ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³", "è¦³å…‰", "åœ°å›³", "æ¡ˆå†…", "äºˆç´„", "ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³", "ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆ",
            "åˆ‡ç¬¦", "ä¹—ã‚Šæ›ãˆ", "å‡ºå£", "å…¥å£", "æ”¹æœ­", "ãƒ›ãƒ¼ãƒ ", "ç‰¹æ€¥", "æ–°å¹¹ç·š", "è·¯ç·š", "çµ‚é›»",
            "ä¸¡æ›¿", "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰", "ç¾é‡‘", "ãƒ¬ã‚·ãƒ¼ãƒˆ", "å…ç¨", "ãŠåœŸç”£", "è¨˜å¿µå“", "å†™çœŸ", "ã‚«ãƒ¡ãƒ©", "ã‚¹ãƒãƒ›"
        ]
    },
    
    # ìŒì‹/ë ˆìŠ¤í† ë‘
    "food": {
        "name": "ìŒì‹/ë ˆìŠ¤í† ë‘",
        "level": "practical",
        "seed_words": [
            "ãƒ©ãƒ¼ãƒ¡ãƒ³", "å¯¿å¸", "å¤©ã·ã‚‰", "ã†ã©ã‚“", "ãã°", "ç„¼è‚‰", "åˆºèº«", "ä¸¼", "å¼å½“", "ãŠã«ãã‚Š",
            "å‘³å™Œæ±", "æ¼¬ç‰©", "è±†è…", "ç´è±†", "æè±†", "é¤ƒå­", "ã‚«ãƒ¬ãƒ¼", "å®šé£Ÿ", "ã‚³ãƒ¼ã‚¹", "ãƒ‡ã‚¶ãƒ¼ãƒˆ",
            "ãƒ¡ãƒ‹ãƒ¥ãƒ¼", "æ³¨æ–‡", "ä¼šè¨ˆ", "ãŠç®¸", "ã‚¹ãƒ—ãƒ¼ãƒ³", "ãƒ•ã‚©ãƒ¼ã‚¯", "ãŠã—ã¼ã‚Š", "ãŠå†·", "ç”Ÿãƒ“ãƒ¼ãƒ«", "æ—¥æœ¬é…’"
        ]
    },
    
    # ì‡¼í•‘
    "shopping": {
        "name": "ì‡¼í•‘",
        "level": "practical",
        "seed_words": [
            "åº—", "å€¤æ®µ", "ã‚»ãƒ¼ãƒ«", "å‰²å¼•", "ç‰¹å£²", "ãƒ¬ã‚¸", "è¢‹", "åŒ…è£…", "ã‚®ãƒ•ãƒˆ", "äº¤æ›",
            "ã‚µã‚¤ã‚º", "è‰²", "åœ¨åº«", "å“åˆ‡ã‚Œ", "å…¥è·", "å–ã‚Šå¯„ã›", "é…é€", "é€æ–™", "è¿”å“", "ä¿è¨¼"
        ]
    },
    
    # ë¹„ì¦ˆë‹ˆìŠ¤
    "business": {
        "name": "ë¹„ì¦ˆë‹ˆìŠ¤ ì¼ë³¸ì–´",
        "level": "professional",
        "seed_words": [
            "ååˆº", "æŒ¨æ‹¶", "æ•¬èª", "è¬™è­²èª", "ä¸å¯§èª", "ãŠè¾å„€", "å•†è«‡", "å¥‘ç´„", "ææ¡ˆ", "ä¼ç”»",
            "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ", "ãƒãƒ¼ãƒ ", "ãƒªãƒ¼ãƒ€ãƒ¼", "ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "éƒ¨é•·", "èª²é•·", "ä¿‚é•·", "ç¤¾é•·", "å–ç· å½¹", "æ ªä¸»"
        ]
    }
}


def load_collected_words() -> Dict:
    """ì €ì¥ëœ ë‹¨ì–´ DB ë¡œë“œ"""
    try:
        if os.path.exists(COLLECTED_WORDS_FILE):
            with open(COLLECTED_WORDS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"[Load Error] {e}")
    
    return {
        "metadata": {
            "version": "2.0.0",
            "last_updated": None,
            "total_words": 0,
            "categories": []
        },
        "words": []
    }


def save_collected_words(data: Dict) -> bool:
    """ë‹¨ì–´ DB ì €ì¥"""
    try:
        data['metadata']['last_updated'] = datetime.now().isoformat()
        data['metadata']['total_words'] = len(data['words'])
        data['metadata']['categories'] = list(set(w.get('category', 'unknown') for w in data['words']))
        
        with open(COLLECTED_WORDS_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"[Save Error] {e}")
        return False


def fetch_word_from_naver(word: str) -> Optional[Dict]:
    """ë„¤ì´ë²„ ê²€ìƒ‰ APIë¡œ ë‹¨ì–´ ì •ë³´ ì¡°íšŒ (ë°±ê³¼ì‚¬ì „ + ì›¹ê²€ìƒ‰)"""
    try:
        enc_text = urllib.parse.quote(word)
        translation = None
        definition = None
        examples = []
        
        # 1. ë°±ê³¼ì‚¬ì „ ê²€ìƒ‰ (ë‹¨ì–´ ì •ì˜)
        try:
            url_encyc = f"https://openapi.naver.com/v1/search/encyc.json?query={enc_text}&display=3"
            
            request = urllib.request.Request(url_encyc)
            request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
            request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
            
            response = urllib.request.urlopen(request, timeout=5)
            
            if response.getcode() == 200:
                res_body = json.loads(response.read().decode('utf-8'))
                items = res_body.get('items', [])
                if items:
                    definition = items[0]['description'].replace("<b>", "").replace("</b>", "")
                    examples = [
                        {"title": item['title'].replace("<b>", "").replace("</b>", ""),
                         "desc": item['description'].replace("<b>", "").replace("</b>", "")}
                        for item in items[:3]
                    ]
        except Exception as e:
            print(f"  [Encyclopedia] {word}: {e}")
        
        # 2. ë¸”ë¡œê·¸ ê²€ìƒ‰ (ì˜ˆë¬¸/í™œìš©)
        try:
            search_query = urllib.parse.quote(f"{word} ì¼ë³¸ì–´ ëœ»")
            url_blog = f"https://openapi.naver.com/v1/search/blog.json?query={search_query}&display=2"
            
            request = urllib.request.Request(url_blog)
            request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
            request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
            
            response = urllib.request.urlopen(request, timeout=5)
            
            if response.getcode() == 200:
                res_body = json.loads(response.read().decode('utf-8'))
                items = res_body.get('items', [])
                if items and not translation:
                    # ë¸”ë¡œê·¸ì—ì„œ ë²ˆì—­ ì¶”ì¶œ ì‹œë„
                    desc = items[0]['description'].replace("<b>", "").replace("</b>", "")
                    if len(desc) > 10:
                        translation = desc[:100] + "..."
        except Exception as e:
            print(f"  [Blog] {word}: {e}")
        
        if definition or translation:
            return {
                "word": word,
                "translation": translation,
                "definition": definition,
                "examples": examples,
                "collected_at": datetime.now().isoformat()
            }
        
    except Exception as e:
        print(f"[Fetch Error] {word}: {e}")
    
    return None


def collect_words_by_category(category_key: str, limit: int = 50) -> List[Dict]:
    """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì—ì„œ ë‹¨ì–´ ìˆ˜ì§‘ (ê¸°ë³¸ 50ê°œ)"""
    if category_key not in COLLECTION_CATEGORIES:
        print(f"Unknown category: {category_key}")
        return []
    
    category = COLLECTION_CATEGORIES[category_key]
    db = load_collected_words()
    existing_words = {w['word'] for w in db['words']}
    
    collected = []
    for word in category['seed_words']:
        if word in existing_words:
            continue
        
        if len(collected) >= limit:
            break
        
        print(f"  [{category_key}] Collecting: {word}")
        word_data = fetch_word_from_naver(word)
        
        if word_data:
            word_data['category'] = category_key
            word_data['category_name'] = category['name']
            word_data['level'] = category.get('level', 'unknown')
            collected.append(word_data)
            
            # API ì†ë„ ì œí•œ ëŒ€ì‘ (0.2ì´ˆ = ì´ˆë‹¹ 5íšŒ)
            time.sleep(0.2)
    
    # ì €ì¥
    if collected:
        db['words'].extend(collected)
        if save_collected_words(db):
            print(f"âœ… [{category_key}] Saved {len(collected)} words")
    
    return collected


def mass_collection(limit_per_category: int = 30) -> int:
    """ëŒ€ëŸ‰ ìˆ˜ì§‘ - ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ í•œêº¼ë²ˆì— ìˆ˜ì§‘"""
    print(f"ğŸš€ Mass Collection Started: {datetime.now()}")
    print(f"   Target: {limit_per_category} words per category")
    
    total_collected = 0
    for category_key in COLLECTION_CATEGORIES.keys():
        collected = collect_words_by_category(category_key, limit=limit_per_category)
        total_collected += len(collected)
        print(f"   [{category_key}] +{len(collected)} words")
    
    print(f"ğŸ“Š Total Collected: {total_collected} words")
    
    # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ í˜¸ì¶œ (ì½”ë“œ ì‚½ì… íŠ¸ë¦¬ê±°)
    try:
        from manifest_updater import update_manifest
        update_manifest()
    except Exception as e:
        print(f"âš ï¸ Manifest Update failed: {e}")
        
    return total_collected


def daily_collection_job():
    """ë§¤ì¼ ì‹¤í–‰í•  ìˆ˜ì§‘ ì‘ì—… - ê° ì¹´í…Œê³ ë¦¬ì—ì„œ 10ê°œì”© ìˆ˜ì§‘"""
    print(f"ğŸŒ… Daily Collection Started: {datetime.now()}")
    return mass_collection(limit_per_category=10)


def get_collected_words(category: str = None, limit: int = 50) -> List[Dict]:
    """ìˆ˜ì§‘ëœ ë‹¨ì–´ ì¡°íšŒ APIìš©"""
    db = load_collected_words()
    words = db['words']
    
    if category:
        words = [w for w in words if w.get('category') == category]
    
    return words[-limit:]


def get_collection_stats() -> Dict:
    """ìˆ˜ì§‘ í†µê³„"""
    db = load_collected_words()
    words = db['words']
    
    stats = {
        "total": len(words),
        "last_updated": db['metadata'].get('last_updated'),
        "by_category": {},
        "by_level": {}
    }
    
    for word in words:
        cat = word.get('category', 'unknown')
        level = word.get('level', 'unknown')
        stats['by_category'][cat] = stats['by_category'].get(cat, 0) + 1
        stats['by_level'][level] = stats['by_level'].get(level, 0) + 1
    
    return stats


# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    print("ğŸ§ª Testing word collector (expanded)...")
    
    # í…ŒìŠ¤íŠ¸: JLPT N5ì—ì„œ 5ê°œ ìˆ˜ì§‘
    collected = collect_words_by_category("jlpt_n5", limit=5)
    print(f"\nCollected {len(collected)} words:")
    for w in collected:
        print(f"  - {w['word']}: {w['translation']}")
    
    # í†µê³„ í™•ì¸
    stats = get_collection_stats()
    print(f"\nStats: {stats}")
